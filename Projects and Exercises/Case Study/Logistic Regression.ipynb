{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as met\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CCData=pd.read_csv(\"CC.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.value_counts(CCData['Class']).plot.bar()\n",
    "plt.title('Fraud Detection Classes histogram')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "CCData['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Fraud Data Points are: 99.83 % of the Data Points.\n",
      "Fraud Data Points are: 0.17 % of the Data Points.\n"
     ]
    }
   ],
   "source": [
    "print('Non Fraud Data Points are:' , round(CCData['Class'].value_counts()[0]/len(CCData)*100, 2), '% of the Data Points.')\n",
    "print('Fraud Data Points are:' , round(CCData['Class'].value_counts()[1]/len(CCData)*100, 2), '% of the Data Points.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler=StandardScaler()\n",
    "CCData['SAmount']=std_scaler.fit_transform(CCData['Amount'].values.reshape(-1,1))\n",
    "CCData['STime']=std_scaler.fit_transform(CCData['Time'].values.reshape(-1,1))\n",
    "CCData.drop(['Time','Amount'],axis=1,inplace=True)\n",
    "SCAmount= CCData['SAmount']\n",
    "SCTime = CCData['STime']\n",
    "CCData.drop(['SAmount', 'STime'], axis=1, inplace=True)\n",
    "CCData.insert(1, 'SAmount', SCAmount)\n",
    "CCData.insert(2, 'STime', SCTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>SAmount</th>\n",
       "      <th>STime</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.996541</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1   SAmount     STime        V2        V3        V4        V5  \\\n",
       "0 -1.359807  0.244964 -1.996583 -0.072781  2.536347  1.378155 -0.338321   \n",
       "1  1.191857 -0.342475 -1.996583  0.266151  0.166480  0.448154  0.060018   \n",
       "2 -1.358354  1.160686 -1.996562 -1.340163  1.773209  0.379780 -0.503198   \n",
       "3 -0.966272  0.140534 -1.996562 -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4 -1.158233 -0.073403 -1.996541  0.877737  1.548718  0.403034 -0.407193   \n",
       "\n",
       "         V6        V7        V8  ...       V20       V21       V22       V23  \\\n",
       "0  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CCData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separation of input variables from target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCFeature_names = CCData.iloc[:, 1:30].columns\n",
    "targetClass = CCData.iloc[:1, 30:].columns\n",
    "\n",
    "CCDataFeatures = CCData[CCFeature_names]\n",
    "CCData_target = CCData[targetClass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAmount</th>\n",
       "      <th>STime</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.342475</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140534</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.996541</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-0.350151</td>\n",
       "      <td>1.641931</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.254117</td>\n",
       "      <td>1.641952</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>-0.081839</td>\n",
       "      <td>1.641974</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.313249</td>\n",
       "      <td>1.641974</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>0.514355</td>\n",
       "      <td>1.642058</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SAmount     STime         V2        V3        V4        V5        V6  \\\n",
       "0       0.244964 -1.996583  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1      -0.342475 -1.996583   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       1.160686 -1.996562  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       0.140534 -1.996562  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4      -0.073403 -1.996541   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...          ...       ...        ...       ...       ...       ...       ...   \n",
       "284802 -0.350151  1.641931  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803 -0.254117  1.641952  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804 -0.081839  1.641974  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805 -0.313249  1.641974   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  0.514355  1.642058  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9  ...       V19       V20       V21  \\\n",
       "0       0.239599  0.098698  0.363787  ...  0.403993  0.251412 -0.018307   \n",
       "1      -0.078803  0.085102 -0.255425  ... -0.145783 -0.069083 -0.225775   \n",
       "2       0.791461  0.247676 -1.514654  ... -2.261857  0.524980  0.247998   \n",
       "3       0.237609  0.377436 -1.387024  ... -1.232622 -0.208038 -0.108300   \n",
       "4       0.592941 -0.270533  0.817739  ...  0.803487  0.408542 -0.009431   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  ... -0.682920  1.475829  0.213454   \n",
       "284803  0.024330  0.294869  0.584800  ... -1.545556  0.059616  0.214205   \n",
       "284804 -0.296827  0.708417  0.432454  ... -0.577252  0.001396  0.232045   \n",
       "284805 -0.686180  0.679145  0.392087  ...  2.897849  0.127434  0.265245   \n",
       "284806  1.577006 -0.414650  0.486180  ... -0.256117  0.382948  0.261057   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \n",
       "0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  \n",
       "1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724  \n",
       "2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  \n",
       "3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  \n",
       "4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731  \n",
       "284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527  \n",
       "284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561  \n",
       "284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533  \n",
       "284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  \n",
       "\n",
       "[284807 rows x 29 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CCDataFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class\n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           0\n",
       "...       ...\n",
       "284802      0\n",
       "284803      0\n",
       "284804      0\n",
       "284805      0\n",
       "284806      0\n",
       "\n",
       "[284807 rows x 1 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CCData_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(CCDataFeatures, CCData_target,train_size = 0.80, test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the  Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weldat/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "Logistic=LogisticRegression()\n",
    "#Training the logistic Regression Model\n",
    "Logistic.fit(X_train, y_train)\n",
    "y_pred = Logistic.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report - Model performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results of Decision Tree Classifier on the Skewed Data! \n",
      "Accuracy :  0.9991573329588147\n",
      "Precision :  0.8305084745762712\n",
      "F-1 Score :  0.6712328767123288\n",
      "Recall/Sensitivity/ Score :  0.5632183908045977\n",
      "Matthews Correlation Coefficient :  0.6835463565545198\n",
      "Balanced classification Rate:  0.7815212833143867\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation Results of Decision Tree Classifier on the Skewed Data! \")\n",
    "# Accuracy\n",
    "print(\"Accuracy : \",met.accuracy_score(y_test, y_pred))\n",
    "#Precision\n",
    "print('Precision : ', met.precision_score(y_test, y_pred))\n",
    "#F-1 Score \n",
    "print('F-1 Score : ',met.f1_score(y_test, y_pred))\n",
    "\n",
    "#Recall= TP / [TP+FN] \n",
    "print('Recall/Sensitivity/ Score : ',met.recall_score(y_test,y_pred))\n",
    "\n",
    "\n",
    "#Matthews Correlation Coefficient \n",
    "print('Matthews Correlation Coefficient : ',met.matthews_corrcoef(y_test, y_pred))\n",
    "\n",
    "#Balanced classification Rate \n",
    "print('Balanced classification Rate: ',met.balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function \"len\" counts the number of classes = 1 and saves it as an object \"fraud_records\"\n",
    "fraud_records = len(CCData[CCData.Class == 1])\n",
    "\n",
    "# Defines the index for fraud and non-fraud in the lines:\n",
    "fraud_indices = CCData[CCData.Class == 1].index\n",
    "not_fraud_indices = CCData[CCData.Class == 0].index\n",
    "\n",
    "# Randomly collect equal samples of each type:\n",
    "under_sample_indices = np.random.choice(not_fraud_indices, fraud_records, False)\n",
    "df_undersampled = CCData.iloc[np.concatenate([fraud_indices, under_sample_indices]),:]\n",
    "X_undersampled = df_undersampled.iloc[:,1:31]\n",
    "Y_undersampled = df_undersampled.Class\n",
    "X_undersampled_train, X_undersampled_test, Y_undersampled_train, Y_undersampled_test = train_test_split(X_undersampled, Y_undersampled, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the \"new\" classifier for balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic=LogisticRegression()\n",
    "#Training the logistic Regression Model\n",
    "Logistic.fit(X_undersampled_train, Y_undersampled_train)\n",
    "yUnder_pred = Logistic.predict(X_undersampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results of Logistic Regression Model on Balanced Data! \n",
      "Accuracy :  0.9898648648648649\n",
      "Precision :  0.986013986013986\n",
      "F-1 Score :  0.9894736842105264\n",
      "Recall/Sensitivity/ Score :  0.9929577464788732\n",
      "Matthews Correlation Coefficient :  0.9797243549251777\n",
      "Balanced classification Rate:  0.9899853667459302\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation Results of Logistic Regression Model on Balanced Data! \")\n",
    "# Accuracy Y_undersampled_test\n",
    "print(\"Accuracy : \",met.accuracy_score(Y_undersampled_test, yUnder_pred))\n",
    "#Precision\n",
    "print('Precision : ', met.precision_score(Y_undersampled_test, yUnder_pred))\n",
    "#F-1 Score \n",
    "print('F-1 Score : ',met.f1_score(Y_undersampled_test, yUnder_pred))\n",
    "\n",
    "#Recall= TP / [TP+FN] \n",
    "print('Recall/Sensitivity/ Score : ',met.recall_score(Y_undersampled_test, yUnder_pred))\n",
    "\n",
    "#Specificity -Similar to Recall but calculates for the Negative Score\n",
    "   # Specificity= TN / [TN+FP] \n",
    "\n",
    "\n",
    "#Matthews Correlation Coefficient \n",
    "print('Matthews Correlation Coefficient : ',met.matthews_corrcoef(Y_undersampled_test, yUnder_pred))\n",
    "\n",
    "#Balanced classification Rate \n",
    "print('Balanced classification Rate: ',met.balanced_accuracy_score(Y_undersampled_test, yUnder_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
